{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf读取csv数据\n",
    "\n",
    "以[1978 年收集的波士顿房价数据集](http://lib.stat.cmu.edu/datasets/boston)为例\n",
    "\n",
    "该数据集包括 506 个样本场景，每个房屋含 14 个特征：\n",
    "1. CRIM：城镇人均犯罪率\n",
    "2. ZN：占地 25000 平方英尺（1 英尺=0.3048 米）以上的住宅用地比例\n",
    "3. INDUS：每个城镇的非零售商业用地比例\n",
    "4. CHAS：查尔斯河（Charles River）变量（若土地位于河流边界，则为 1；否则为 0）\n",
    "5. NOX：一氧化氮浓度（每千万）\n",
    "6. RM：每个寓所的平均房间数量\n",
    "7. AGE：1940 年以前建成的自住单元比例\n",
    "8. DIS：到 5 个波士顿就业中心的加权距离\n",
    "9. RAD：径向高速公路可达性指数\n",
    "10. TAX：每万美元的全价值物业税税率\n",
    "11. PTRATIO：镇小学老师比例\n",
    "12. B：1000(Bk-0.63)2，其中 Bk 是城镇黑人的比例\n",
    "13. LSTAT：低地位人口的百分比\n",
    "14. MEDV：1000 美元自有住房的中位值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里先定义好需要读的文件名以及对应的batch大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile = '../DataSet/boston_housing.csv'\n",
    "BatchSize = 10\n",
    "NumFeatures = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(filenames):\n",
    "\n",
    "    # 数据队列，用一个列表来表示\n",
    "    f_queue = tf.train.string_input_producer(filenames)\n",
    "    reader = tf.TextLineReader()\n",
    "\n",
    "    # 读取其中的值\n",
    "    key, value = reader.read(f_queue)\n",
    "    \n",
    "    # 指定一些默认数据\n",
    "    record_defaults = [[0.0] for _ in range(NumFeatures)]\n",
    "\n",
    "    # 用tf.decode_csv方法来解析前面读到的值\n",
    "    data = tf.decode_csv(value, record_defaults = record_defaults)\n",
    "    \n",
    "    # 将5，10，12列的数据聚合起来\n",
    "    features = tf.stack(tf.gather_nd(data, [[5], [10], [12]]))\n",
    "\n",
    "    # 最后一列作为它的label\n",
    "    label = data[-1]\n",
    "    \n",
    "    min_after_dequeue = 10 * BatchSize\n",
    "    # 队列中的最大样本数量\n",
    "    capacity = 20 * BatchSize\n",
    "\n",
    "    # 产生BatchSize数量的样本，并进行打乱操作\n",
    "    feature_batch, label_batch = tf.train.shuffle_batch([features, label], \n",
    "                                                        batch_size = BatchSize,\n",
    "                                                       capacity = capacity,\n",
    "                                                       min_after_dequeue = min_after_dequeue)\n",
    "    # 将做好的batch返回\n",
    "    return feature_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_batch, label_batch = data_generator([DataFile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'shuffle_batch:1' shape=(10,) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上就把csv数据读入了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(sess.run(label_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
