{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf网络参考格式\n",
    "\n",
    "前面介绍了许多tf的基本用法，包括张量的概念、tensorboard等，本节就做一套tf搭建DNN，对MNIST数据集进行分类的参考流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib.layers import fully_connected\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-9c5846cd70ef>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/zsf/opt/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/zsf/opt/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../DataSet/MNIST/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/zsf/opt/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../DataSet/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting ../DataSet/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../DataSet/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/zsf/opt/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# 加载MNIST数据集\n",
    "mnist = input_data.read_data_sets(\"../DataSet/MNIST/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练几轮\n",
    "epochs = 10\n",
    "\n",
    "# 一个batch的数据大小\n",
    "batch_size = 50\n",
    "\n",
    "# 迭代次数\n",
    "iterations = mnist.train.num_examples // batch_size\n",
    "\n",
    "# 学习率\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络结构参数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST图像输入维度\n",
    "n_inputs = 28*28\n",
    "\n",
    "# 隐藏层1的维度\n",
    "n_hidden1 = 300\n",
    "\n",
    "# 隐藏层2的维度\n",
    "n_hidden2 = 100\n",
    "\n",
    "# 输出层的维度\n",
    "n_outputs= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入数据的placeholder\n",
    "x = tf.placeholder(tf.float32, shape=(None, n_inputs), name='x')\n",
    "# label的placeholder\n",
    "y = tf.placeholder(tf.int64, shape=(None), name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建三层神经网络\n",
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = tf.contrib.layers.fully_connected(x, \n",
    "                                                n_hidden1, \n",
    "                                                activation_fn=tf.nn.relu, \n",
    "                                                scope='hidden1')\n",
    "    \n",
    "    hidden2 = tf.contrib.layers.fully_connected(hidden1, \n",
    "                                                n_hidden2, \n",
    "                                                activation_fn=tf.nn.relu, \n",
    "                                                scope='hidden2')\n",
    "    \n",
    "    logits = tf.contrib.layers.fully_connected(hidden2, \n",
    "                                               n_outputs, \n",
    "                                               activation_fn=None, \n",
    "                                               scope='logits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    # 计算交叉熵loss\n",
    "    entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, \n",
    "                                                             logits = logits)\n",
    "    # 对一个batch内的loss求平均\n",
    "    loss = tf.reduce_mean(entropy, name='loss')\n",
    "    tf.summary.scalar('loss', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建训练算子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "    train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('metrics'):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    acc = tf.reduce_mean(tf.cast(correct, tf.float32), name='acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练及保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Saver-1: 模型保存，默认保存所有参数\n",
    "saver = tf.train.Saver()    \n",
    "\n",
    "# Summary-1: 将所有的summary进行merge操作\n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Train_acc:', 0.907327270175923, 'Eval_acc', 0.9558)\n",
      "(2, 'Train_acc:', 0.9598909088698301, 'Eval_acc', 0.9708)\n",
      "(3, 'Train_acc:', 0.9719818193804134, 'Eval_acc', 0.9734)\n",
      "(4, 'Train_acc:', 0.9787818213484504, 'Eval_acc', 0.976)\n",
      "(5, 'Train_acc:', 0.9842545495791869, 'Eval_acc', 0.9782)\n",
      "(6, 'Train_acc:', 0.9875818223303015, 'Eval_acc', 0.979)\n",
      "(7, 'Train_acc:', 0.9905818216909061, 'Eval_acc', 0.9806)\n",
      "(8, 'Train_acc:', 0.9927454582127658, 'Eval_acc', 0.9812)\n",
      "(9, 'Train_acc:', 0.9950909123095599, 'Eval_acc', 0.9802)\n",
      "(10, 'Train_acc:', 0.9967272750355981, 'Eval_acc', 0.9818)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Summary-2: 定义summary_writer\n",
    "    summary_writer = tf.summary.FileWriter('./logs', sess.graph)\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        acc_train = 0.0\n",
    "        \n",
    "        for iteration in range(iterations):\n",
    "            # 产生下一个batch的数据\n",
    "            x_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # Summary-3: 运算summary_op\n",
    "            _, acc_batch, summary_str = sess.run([train, acc, summary_op], feed_dict={x:x_batch, y:y_batch})\n",
    "            \n",
    "            # Summary-4: 将summary_str写出去\n",
    "            summary_writer.add_summary(summary_str, iteration)\n",
    "            \n",
    "            acc_train += acc_batch\n",
    "        \n",
    "        # 验证集\n",
    "        acc_eval = sess.run(acc, feed_dict={x:mnist.validation.images, y:mnist.validation.labels})\n",
    "        \n",
    "        print(epoch+1, \n",
    "              'Train_acc:', \n",
    "              acc_train/iterations, \n",
    "              'Eval_acc', \n",
    "              acc_eval)\n",
    "        \n",
    "    # Saver-2: 将模型保存在此路径下\n",
    "    saver.save(sess, './model/dnn.ckpt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/dnn.ckpt\n",
      "Acc_test:0.979099988937\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model/dnn.ckpt')\n",
    "    \n",
    "    acc_test = acc.eval(feed_dict={x:mnist.test.images, y: mnist.test.labels})\n",
    "    \n",
    "    print(\"Acc_test:{0}\".format(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
